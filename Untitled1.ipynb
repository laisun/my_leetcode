{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_EMB_NAME = 'easytc_embedding'\n",
    "\n",
    "def make_embedding(inputs,\n",
    "                   vocab_size: int,\n",
    "                   embed_size: int,\n",
    "                   maxlen: int,\n",
    "                   weights=None):\n",
    "    \"\"\"A simple wrapper function to create embedding. \n",
    "    All it dose is check whether to initialize with weights.\n",
    "\n",
    "    Arguments:\n",
    "        vocab_size {int} -- vocab size\n",
    "        embed_size {int} -- embed size\n",
    "        maxlen {int} -- max seqence length\n",
    "\n",
    "    Keyword Arguments:\n",
    "        weights {None or np array} -- Initialize weight of embedding.  (default: {None})\n",
    "\n",
    "    Returns:\n",
    "        Tensor -- Embedding tensor\n",
    "    \"\"\"\n",
    "\n",
    "    if weights is not None:\n",
    "        embed = tf.keras.layers.Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embed_size,\n",
    "            input_length=maxlen,\n",
    "            weights=[weights],\n",
    "            name=DEFAULT_EMB_NAME)(inputs)\n",
    "    else:\n",
    "        embed = tf.keras.layers.Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embed_size,\n",
    "            input_length=maxlen,\n",
    "            name=DEFAULT_EMB_NAME)(inputs)\n",
    "    return embed\n",
    "\n",
    "\n",
    "def textcnn(num_classes, vocab_size, embed_size, maxlen,\n",
    "            num_filters, filter_sizes, dropout_rate=0.5,\n",
    "            embedding_matrix=None):\n",
    "    \"\"\" implemantion of CNN for sentence classification.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(maxlen,))\n",
    "    embed = make_embedding(inputs,\n",
    "                           vocab_size=vocab_size,\n",
    "                           embed_size=embed_size,\n",
    "                           maxlen=maxlen,\n",
    "                           weights=embedding_matrix)\n",
    "\n",
    "    pooled_outputs = []\n",
    "    for fz in filter_sizes:\n",
    "        conv = tf.keras.layers.Conv1D(\n",
    "                      num_filters, fz,\n",
    "                      padding='valid',\n",
    "                      activation=\"relu\")(embed)\n",
    "        pool = tf.keras.layers.GlobalMaxPooling1D()(conv)\n",
    "        #pool = KMaxPooling(k=2)(conv)\n",
    "        pooled_outputs.append(pool)\n",
    "    h_pool = tf.keras.layers.Concatenate()(pooled_outputs)\n",
    "\n",
    "    dense = tf.keras.layers.Dense(num_classes)(h_pool)\n",
    "    dropout = tf.keras.layers.Dropout(1-dropout_rate)(dense)\n",
    "    outputs = tf.keras.layers.Activation('softmax')(dropout)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lx/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/lx/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "easytc_embedding (Embedding)    (None, 50, 50)       500000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 49, 150)      15150       easytc_embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 48, 150)      22650       easytc_embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 47, 150)      30150       easytc_embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 150)          0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 150)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 150)          0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 450)          0           global_max_pooling1d[0][0]       \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            902         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2)            0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 2)            0           dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 568,852\n",
      "Trainable params: 568,852\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "m = textcnn(num_classes=2, vocab_size=10000, embed_size=50, maxlen=50,\n",
    "            num_filters=150, filter_sizes=[2,3,4])\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(450+1)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinimalRNNCell(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units, **kwargs):\n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        super(MinimalRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='kernel')\n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=(self.units, self.units),\n",
    "            initializer='uniform',\n",
    "            name='recurrent_kernel')\n",
    "        \n",
    "        self.bias = self.add_weight(\n",
    "            shape=(1, self.units),\n",
    "            initializer='uniform',\n",
    "            name='recurrent_kernel')\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        prev_output = states[0]\n",
    "        h = K.dot(inputs, self.kernel)\n",
    "        output = h + K.dot(prev_output, self.recurrent_kernel) + self.bias\n",
    "        return output, [output]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 10, 5)]           0         \n",
      "_________________________________________________________________\n",
      "rnn_1 (RNN)                  (None, 10)                160       \n",
      "=================================================================\n",
      "Total params: 160\n",
      "Trainable params: 160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(10,5,))\n",
    "rnn = tf.keras.layers.RNN(MinimalRNNCell(10))\n",
    "outputs = rnn(inputs)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "  \n",
    "    # 将 sin 应用于数组中的偶数索引（indices）；2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    # 将 cos 应用于数组中的奇数索引；2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    return pos_encoding\n",
    "\n",
    "res = positional_encoding(100, 10)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 512)\n",
      "(100, 512)\n"
     ]
    }
   ],
   "source": [
    "# 生成d_model的 1/（10000^(2i/dmodel))\n",
    "length = 100\n",
    "d_model = 512\n",
    "\n",
    "pos = np.array([[i] for i in range(length)]) # (length, 1)\n",
    "\n",
    "d_is = np.arange(d_model)\n",
    "rates = 1 / np.power(10000, 2*(d_is//2) / np.float32(d_model))\n",
    "rates = np.expand_dims(rates, axis=0) # (1, d_model)\n",
    "\n",
    "pes = pos * rates\n",
    "print(pes.shape) # (length, d_model)\n",
    "\n",
    "pes[:, 0::2] = np.sin(pes[:, 0::2]) # 2i 位置sin变换\n",
    "pes[:, 1::2] = np.sin(pes[:, 1::2]) # 2i+1 位置cos变换\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n",
      "[5.00000000e+00 5.00000000e+00 7.92446596e-01 7.92446596e-01\n",
      " 1.25594322e-01 1.25594322e-01 1.99053585e-02 1.99053585e-02\n",
      " 3.15478672e-03 3.15478672e-03]\n"
     ]
    }
   ],
   "source": [
    "angle_rads = get_angles(np.arange(100)[:, np.newaxis],\n",
    "                        np.arange(10)[np.newaxis, :],\n",
    "                        10)\n",
    "print(angle_rads.shape)\n",
    "print(angle_rads[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "i = np.arange(10)[np.newaxis, :]\n",
    "print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "print(angle_rates.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.arange(100)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pos*angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "print(r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50)\n",
      "[0.43278054 0.57456335 0.43982745 0.56008432 0.56474883 0.50937905\n",
      " 0.42628247 0.55650716 0.41340909 0.47868524 0.44457602 0.427981\n",
      " 0.44789383 0.49969561 0.46462884 0.51235246 0.49596763 0.43443592\n",
      " 0.53966605 0.4748008  0.59409979 0.59771888 0.51035007 0.52228274\n",
      " 0.59524209 0.49502827 0.50830026 0.47618258 0.54661573 0.48640033\n",
      " 0.34033975 0.52204994 0.65990259 0.42549693 0.46292148 0.37291171\n",
      " 0.53471167 0.47048881 0.65243824 0.47722346 0.46430436 0.52954279\n",
      " 0.44462303 0.56845949 0.48579302 0.50170649 0.52376332 0.49521957\n",
      " 0.61476987 0.46595983]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    v = np.exp(x - x.max(axis=-1, keepdims=True))    \n",
    "    return v / v.sum(axis=-1, keepdims=True)\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "    qk = np.matmul(q, np.transpose(k)) # matmul\n",
    "    dk = k.shape[-1]\n",
    "    s_a_l = qk / np.sqrt(dk) # scale\n",
    "    if mask:\n",
    "        s_a_l += (mask*-1e9) # mask\n",
    "    attention_weights = softmax(s_a_l) # softmax\n",
    "    output = np.matmul(attention_weights, v)\n",
    "    return output\n",
    "\n",
    "q = np.random.rand(10,10)\n",
    "k = np.random.rand(20,10)\n",
    "v = np.random.rand(20,50)\n",
    "\n",
    "output = scaled_dot_product_attention(q, k, v)\n",
    "\n",
    "print(output.shape)\n",
    "print(output[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3]\n",
      " [6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2, -1,  0],\n",
       "       [-2, -1,  0]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2,3], [4,5,6]])\n",
    "print(x.max(axis=-1, keepdims=True))\n",
    "x - x.max(axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2, -1,  0])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3]) - np.array([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
